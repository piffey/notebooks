{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports and Configuration\n",
    "\n",
    "There are a few things happening here. One is the use of `nest_asyncio` which is required for Jupyter to be capable of async operations due to some nesting magic that it handles. The next bit is `dotenv` that handles our sensitive login information and such in an env file that it loads into the OS environment variables. This keeps us from storing secrets in this repository on accident. The gitignore file handles the rest keeping that out of the way. I like to separate the imports and configuration out so we can quickly reload them if we need to change anything up or add new libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import domaintools\n",
    "import dotenv\n",
    "import nest_asyncio\n",
    "import pandas\n",
    "import pyasn\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "nest_asyncio.apply()\n",
    "dotenv.load_dotenv()\n",
    "dt_api_user = os.getenv('DT_API_USER')\n",
    "dt_api_key = os.getenv('DT_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Iris hash here.\n",
    "iris_hash = ''\n",
    "\n",
    "dt = domaintools.API(dt_api_user, dt_api_key)\n",
    "results = dt.iris_investigate(search_hash=iris_hash)\n",
    "\n",
    "hosting_history = dict()\n",
    "for result in tqdm(results):\n",
    "    domain = result['domain']\n",
    "    hosting_history[domain] = { 'ip_history': dt.hosting_history(domain).setdefault('ip_history', list()),\n",
    "                                'nameserver_history': dt.hosting_history(domain).setdefault('nameserver_history', list()),\n",
    "                                'registrar_history': dt.hosting_history(domain).setdefault('registrar_history', list()) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get unique counts of all nameservers, ips, and registrars per domain. They are broken out in weird, verbose ways here so we can manipulate\n",
    "# them in later cells if we decide to modify or futz with the data. Just feeling the need to let you know my non-notebook code is not this bad...\n",
    "\n",
    "hosting_history_unique = dict()\n",
    "for domain in hosting_history.keys():\n",
    "    for history_type in hosting_history[domain].keys():\n",
    "        for history_count, history in enumerate(hosting_history[domain][history_type]):\n",
    "            # For some reason our JSON is assumed a string of [] when empty instead of as an empty list.\n",
    "            if type(history) == str:\n",
    "                continue\n",
    "                \n",
    "            for key in history.keys():\n",
    "                if key.startswith('pre_') or key.startswith('post_') or key == 'registrar':\n",
    "                    if hosting_history[domain][history_type][history_count][key] is not None:\n",
    "                        hosting_history_unique.setdefault(domain, dict()).setdefault(f'{history_type}_unique', set()).add(hosting_history[domain][history_type][history_count][key])\n",
    "\n",
    "# Now we want all of these unique counts as well so we can work with it later as well.\n",
    "\n",
    "total_history_counts = dict()\n",
    "for domain in hosting_history_unique.keys():\n",
    "    for history_type in hosting_history_unique[domain].keys():       \n",
    "        for history in hosting_history_unique[domain][history_type]:\n",
    "            total_history_counts[history_type][history] = total_history_counts.setdefault(history_type, dict()).setdefault(history, 0) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show counts tables for each of IPs, registrars, and nameservers.\n",
    "\n",
    "for history_type in total_history_counts.keys():\n",
    "    \n",
    "    table = list()\n",
    "    \n",
    "    # This is the kind of clever thing that would annoy the shit out of me in code, but it will generate us a nice column name in the dataframe\n",
    "    # from what we already have and does it in a way so I don't have to write it three times. Basically just takes the string, finds the first\n",
    "    # occurence of the _ and dumps the rest treating it like a list as you can do in Python. Don't blame me. Blame Guido.\n",
    "    \n",
    "    for key, value in total_history_counts[history_type].items():\n",
    "        table.append([key, value])\n",
    "        \n",
    "    pandas.DataFrame(table, columns=[history_type[:history_type.find('_')], 'counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = list()\n",
    "for key,value in total_history_counts['ip_history_unique'].items():\n",
    "    table.append([key, value])\n",
    "    \n",
    "pandas.DataFrame(table, columns=[\"ip\", \"counts\"]).sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = list()\n",
    "for key,value in total_history_counts['registrar_history_unique'].items():\n",
    "    table.append([key, value])\n",
    "    \n",
    "pandas.DataFrame(table, columns=[\"registrar\", \"counts\"]).sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = list()\n",
    "for key,value in total_history_counts['nameserver_history_unique'].items():\n",
    "    table.append([key, value])\n",
    "    \n",
    "pandas.DataFrame(table, columns=[\"nameserver\", \"counts\"]).sort_values(by='counts', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Passive DNS\n",
    "\n",
    "In this section we take all of the passive DNS A records associated with these domains and compile a table of each domain of:\n",
    "\n",
    "DNS Name, First Seen, ASN at time of First Seen, Last Seen, ASN at time of Last Seen\n",
    "\n",
    "This uses the pyasn library and the collections of historical ASNs from multiple datasets. This data has to be loaded in a specific way for this to work so see the README.md of this dockerized Jupyter instance to see how to populate the data therein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# URLScan\n",
    "\n",
    "Simply query URLScan for all of these domains, pull the images, and load them up in Jupyter using the interact widget as described at https://stackoverflow.com/questions/51546983/embedding-slideshow-in-jupyter-notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VirusTotal\n",
    "\n",
    "Hit VT with all of these domains and pull back any interesting information on them. Perhaps in the future we can interactively build a VTGraph of everything we've compiled here through the new v3 API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
